{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b78589-3231-4c8d-a42c-9535fb18a25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0935225-cce6-43bf-bc14-36264b71d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Add\n",
    "from keras.layers import Input, Conv2D, ZeroPadding2D, Flatten, AveragePooling2D, Dense, Activation\n",
    "from keras import activations\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc46e2a-f4c2-4c4a-b854-bc3806781701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fee1dc3-a112-434b-a348-1db04e5c7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9021eeaf-a678-4749-abd8-b3b280edb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "electronsFile = 'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
    "photonsFile = 'SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5'\n",
    "electrons = h5py.File(electronsFile, 'r')\n",
    "photons = h5py.File(photonsFile, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0894c801-ab41-4098-9b4e-45c8f9e962af",
   "metadata": {},
   "outputs": [],
   "source": [
    "electronX = electrons['X']\n",
    "electronY = electrons['y']\n",
    "photonX = photons['X']\n",
    "photonY = photons['y']\n",
    "X = np.concatenate((electronX, photonX))\n",
    "y = np.concatenate((electronY, photonY))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3ff711-f6a9-4ee7-af34-084dd95304e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249000, 32, 32, 2)\n",
      "(249000, 32, 32, 2)\n"
     ]
    }
   ],
   "source": [
    "# hits = plt.imshow(electronX[0][:,:,0])\n",
    "# times = plt.imshow(electronX[0][:,:,1])\n",
    "\n",
    "print(np.shape(electronX))\n",
    "print(np.shape(photonX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8983ab20-af6c-477f-a8a8-6f28600f1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398400, 32, 32, 2)\n",
      "(398400,)\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(X_train[0, :, :, :]))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))\n",
    "X_train = X_train.reshape(-1, 32, 32, 2)\n",
    "X_test = X_test.reshape(-1, 32, 32, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398081c5-97ff-4dc3-ba83-851117fdff79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21650c32190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hits = plt.imshow(electronX[0][:,:,0])\n",
    "plt.imshow(X[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd70a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b3d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef195ba1-6c93-47c6-9113-f9c3ad4e6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ResNet50 Model\n",
    "#\n",
    "x_dim = 32\n",
    "y_dim = 32\n",
    "num_channels = 2\n",
    "\n",
    "def res_identity(x, filters):\n",
    "    x_skip = x # this will be used for addition with the residual block\n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters):\n",
    "\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut\n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "\n",
    "    input_im = Input(shape=(x_dim, y_dim, num_channels)) # cifar 10 images size\n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    #2nd stage\n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1, activation='sigmoid', kernel_initializer='he_normal')(x) #multi-class\n",
    "\n",
    "    # define the model\n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "# def create_model():\n",
    "#     model = Sequential([\n",
    "#         Conv2D(filters=4, kernel_size=(2, 2), input_shape=(32, 32, 2)),\n",
    "#         Activation('relu'),\n",
    "#         Flatten(),\n",
    "#         Dense(units=8, activation='relu'),\n",
    "#         Dense(units=1, activation='softmax')\n",
    "#     ])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c562b73a-9014-4d35-abcd-f34fc585f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78653c7a-4a9c-49c7-b5bc-0258c91dc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients\n        self._create_all_weights(var_list)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:117 _create_slots\n        self.add_slot(var, 'm')\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n        weight = tf.Variable(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n        return previous_getter(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:145 __call__\n        return tf.zeros(shape, dtype)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2915 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2976 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:240 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 25\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# model.compile(loss='categorical_crossentropy',\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#                   optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule),\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#                   metrics = ['accuracy'])\u001b[39;00m\n\u001b[0;32m     23\u001b[0m es \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# val_accuracy = history.history['val_accuracy']\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients\n        self._create_all_weights(var_list)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:117 _create_slots\n        self.add_slot(var, 'm')\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n        weight = tf.Variable(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n        return previous_getter(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:145 __call__\n        return tf.zeros(shape, dtype)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2915 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2976 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:240 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    C:\\Users\\Jason\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[3,3,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameters ###\n",
    "n_epochs = 5\n",
    "init_lr = 7.5e-2\n",
    "# init_lr = float(sys.argv[1])\n",
    "decay_rate = 0.99\n",
    "# decay_rate = float(sys.argv[2])\n",
    "decay_steps = 100_000\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#                     initial_learning_rate = init_lr,\n",
    "#                     decay_steps = decay_steps,\n",
    "#                     decay_rate = decay_rate)\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "#                   metrics = ['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = n_epochs, verbose = 1)\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "# val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# learning_rate = history.history['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "# val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4f020-fcb4-42b0-be46-d663b6b143fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "# val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(8, 6))\n",
    "\n",
    "ax[0].set_title('Training/Validation Accuracy vs. Epochs')\n",
    "ax[0].plot(train_accuracy, '--', label='Train Accuracy')\n",
    "# ax[0].plot(val_accuracy, '--', label='Validation Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(loc='best')\n",
    "\n",
    "ax[1].set_title('Training/Validation Loss vs. Epochs')\n",
    "ax[1].plot(train_loss, '--', label='Train Loss')\n",
    "# ax[1].plot(val_loss, '--', label='Validation Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349e45d-2b59-4073-bbea-63d709216563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
